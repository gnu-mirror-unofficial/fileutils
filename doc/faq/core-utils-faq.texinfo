\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename core-utils-faq.info
@settitle GNU Core Utilities Frequently Asked Questions
@c %**end of header

@c $Revision: 1.4 $ $Date: 2001/12/05 17:27:19 $

@node Top, Three packages are confusing!, (dir), (dir)
@top
@chapter GNU Core Utilities Frequently Asked Questions

Welcome to the GNU Core Utililities FAQ.  This document answers the most
frequently asked questions about the GNU core utilities.

If you have a question that is not answered in this FAQ then please
check the mailing list archives.  If you find a useful question and
answer please send a message to the bug list and I will add it to the
FAQ so that this document can be improved.  If you still don't find a
suitable answer, consider posting the question to the bug lists.

It is possible that replacing this document, or perhaps in addition to
it, that we might implement a
@uref{http://www.usenix.org/publications/login/1998-6/faq.html,FAQ-o-matic}
type system.  I am interested in any comments you might have on this
topic.

This FAQ was written by Bob Proulx
@uref{mailto:bob@@proulx.com,<bob@@proulx.com>} as an amalgamation of
the many questions asked and answered on the bug lists.

Copyright (C) 2001 Free Software Foundation

This document is free documentation; you can redistribute it and/or
modify it under the terms of the GNU General Public License as published
by the Free Software Foundation; either version 2 of the License, or (at
your option) any later version.

This document and any included programs in the document are distributed
in the hope that they will be useful, but WITHOUT ANY WARRANTY; without
even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
PURPOSE.  See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along
with this program; if not, write to the Free Software Foundation, Inc.,
59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.

An online version is available at
@uref{http://www.gnu.org/licenses/licenses.html}.

@menu
* Three packages are confusing!::
* Where can I get more information about GNU Core Utils?::
* Where can I get the latest version of GNU fileutils?::
* How do I add a question to the FAQ?::
* How do I report a bug?::
* I use the Cygwin port and I have a problem.::
* Why can only root chown files?::
* chown fails when the username contains a '.' in it.::
* How do I remove files that start with a '-' such as '-i'?::
* I have a file called '--help'::
* I have a file '-f' and it affects rm.::
* Why doesn't rm -r *.pattern recurse like it should?::
* Why don't the utilities have built in directory recursion?::
* ls -d does not list directories!::
* Argument list too long::
* I am trying to compile a C program ...::
* I am having a problem with kill::
* Sort does not sorting in normal order!::
* The ls command is not listing files in a normal order!::
* The date command is not working right.::
* ln -s did not link my files together::
* How do I change the ownership or permissions of a symlink?::
* Value too large for defined data type::
* Tar created a Large File but I can't remove it.::
@end menu

@c ---------------------------------------------------------------------------
@node  Three packages are confusing!, Where can I get more information about GNU Core Utils?, Top, Top
@chapter Three packages are confusing!

Together the three packages combined implement a core set of GNU
utilities.  Hereafter in this document we will refer to them as the core
utilities without further enumeration.  But if you know the path or mail
address of one utilities you can transform it into the other utility
name with no difficulty.

@table @uref
@item http://www.gnu.org/software/fileutils/
The official @code{fileutils} home page.

@item http://www.gnu.org/software/shellutils/
The official @code{sh-utils} home page.

@item http://www.gnu.org/software/textutils/
The official @code{textutils} home page.
@end table

@c ---------------------------------------------------------------------------
@node  Where can I get more information about GNU Core Utils?, Where can I get the latest version of GNU fileutils?, Three packages are confusing!, Top
@chapter Where can I get more information about GNU Core Utils?

The online @code{info} documentation is always the most up to date
source of information.  It should always be consulted first for the most
up to date information on your particular installation.  Here are
example commands to invoke @command{info} to browse the documentation.

@example
    info File
    info Shell
    info Text
@end example

Please browse the mailing list archives.  It is possible, even likely,
that your question has been asked before.  You might find just the
information you were looking for.  Many questions are asked here and at
least a few are answered.

@table @uref
@item http://mail.gnu.org/pipermail/bug-fileutils/
The File Utilities mailing list archives of the bug list.

@item http://mail.gnu.org/pipermail/bug-sh-utils/
The Shell Utilities mailing list archives of the bug list.

@item http://mail.gnu.org/pipermail/bug-textutils/
The Text Utilities mailing list archives of the bug list.
@end table

Here are the top level list manager pages for these lists.

@table @uref
@item http://mail.gnu.org/mailman/listinfo/bug-fileutils
Otherwise known as @uref{mailto:bug-fileutils@@gnu.org,
<bug-fileutils@@gnu.org>}, This is the bug list for the GNU File
Utilities.

@item http://mail.gnu.org/mailman/listinfo/bug-sh-utils
Otherwise known as @uref{mailto:bug-sh-utils@@gnu.org,
<bug-sh-utils@@gnu.org>}, This is the bug list for the GNU Shell
Utilities.

@item http://mail.gnu.org/mailman/listinfo/bug-textutils
Otherwise known as @uref{mailto:bug-textutils@@gnu.org,
<bug-textutils@@gnu.org>}, This is the bug list for the GNU Text
Utilities.
@end table

Whew!  Now that we have all of the enurations over with we can refer to
these solely by the combined name of GNU Core Utilities.  But perhaps I
will still slip and refer to one or the other at times.  If I do, please
forgive me and make do.

@c ---------------------------------------------------------------------------
@node Where can I get the latest version of GNU fileutils?, How do I add a question to the FAQ?, Where can I get more information about GNU Core Utils?, Top
@chapter Where can I get the latest version of GNU Core Utils?

Okay I was wrong.  There is still another enumerated list of locations.
The GNU Utilities source code can always be downloaded by FTP from
@uref{ftp://ftp.gnu.org/pub/gnu/} and then selecting the appropriate
subdirectory named after the package.  Here is the complete list.

@table @uref
@item ftp://ftp.gnu.org/pub/gnu/fileutils
The File Utilities main ftp site.

@item ftp://ftp.gnu.org/pub/gnu/sh-utils
The Shell Utilities main ftp site.

@item ftp://ftp.gnu.org/pub/gnu/textutils
The Text Utilities main ftp site.
@end table

Development releases of GNU fileutils source code can be downloaded from
@uref{ftp://alpha.gnu.org/gnu/fetish}.  These are test releases and
although are generally of good quality have not been tested well enough
to be considered release quality.  Use with care.  When possible it
helps to report any bugs as seen against those versions as those are the
ones in current development.

@c ---------------------------------------------------------------------------
@node How do I add a question to the FAQ?, How do I report a bug?, Where can I get the latest version of GNU fileutils?, Top
@chapter How do I add a question to the FAQ?

Send a plain text e-mail to one of the bug lists enumerated above.  Also
with the answer if you have one.  Do @emph{not} send HTML encoded
messages.  Please allow some time for processing.  Many people read the
mail so please try to be concise.  Even if you do not receive a personal
response your message will have been read by the maintainers.  But so
many messages are posted that it can be overwhelming for us at times.

@c ---------------------------------------------------------------------------
@node How do I report a bug?, I use the Cygwin port and I have a problem., How do I add a question to the FAQ?, Top
@chapter How do I report a bug?

Please be sure that the bug you are reporting is actually related to the
GNU utilities.  Many times people report problems in other unrelated
programs.  Those may be legitimate bugs but the GNU utilities
maintainers are in no position to be able to do anything about other
people's software.  People have reported bugs in their sound cards and
crashes of their disk drives and panics of their operating system
kernel.  We can't help you about any of those things.

If possible please test for the presence of your problem using the
latest version of the software.  The GNU utilities are widely used and
many times the bug will already have been found and fixed in a later
version.  Check the mailing list archives to see if someone else has
already reported your problem.  Keep in mind that many people will be
reading the list and it can be difficult to keep up with the volume
repeats.

If you think you have a real bug then send mail to the bug discussion
list.  Use a subject that is descriptive of the issue.  Think of how
difficultit is to follow a thread of discussion when every subject line
is simply @strong{bug}.

Good examples:
@example
    mv && hardlinks problem
    dd and skip on Linux tape devices and pipes
    assertion failure in mv command
    fails to compile on platform xyz
@end example

Bad examples:
@example
    question?
    help!
    bug report
@end example

In your description indicate the version of the program that you are
seeing with the problem.  Also note the operating system type and
version.  The GNU utilities run on many different types of systems and
some problems will be unique to them.  We are good at guessing your
environment but it is much simpler if we have the information without
guessing.

Include as small of a test case as you can manage to create that will
allow others to recreate the problem.  If the problem cannot be
recreated then it is very difficult to diagnose or fix.

Patches to the source code are always appreciated.  But even if you do
not feel comfortable at the source code level reports of bugs are always
welcome.

@c ---------------------------------------------------------------------------
@node I use the Cygwin port and I have a problem., Why can only root chown files?, How do I report a bug?, Top
@chapter I use the Cygwin port and I have a problem.

The hard work the Cygwin team has put in to porting the GNU utilities to
Windows is greatly admired.  However the GNU team generally uses UNIX
systems and do not have access to Cygwin systems.  Most of us can't
help.  It would be most appreciated if you would make your bug report
directly to the Cygwin folks.  They are the experts and best suited to
handle the problem.

@table @uref
@item http://sources.redhat.com/cygwin/
Cygwin Home Page

@item http://sources.redhat.com/cygwin/bugs.html
Cygwin Bug Report Guidelines.  This is a good reference for general bug
reporting.
@end table

@c ---------------------------------------------------------------------------
@node Why can only root chown files?, chown fails when the username contains a '.' in it., I use the Cygwin port and I have a problem., Top
@chapter Why can only root chown files?

Actually, the GNU chown command does not know if this is the policy of
the system or not.  It calls the kernel system call chown() just like
any other program (e.g. perl, ruby, etc.)  If the OS allows it then it
will change the ownership of the file.  Different systems handle this
differently.  Traditional System V UNIX systems allow anyone to give a
file away to other owners.  On those systems GNU chown does change the
ownership of files.

But on most modern systems BSD symantics are followed and only the
superuser can change the ownership of the file.  The problem for
documenting this is that GNU chown does not know which it will be
running on.  It could be one or it could be the other.  Or it might even
be running on a system without the concept of file ownership at all!
This is really an OS policy decision and it is hard to track
documentation to be different on different systems.

The reason to restrict ownership is mostly threefold.  One is that
people have used this to avoid disk space quota restrictions.  Give the
file to someone (like root) with disk quota to spare.  Two is that you
can deny someone service by using all of their quota until they cannot
create any files.  Three is that a user can create files that they
cannot remove.

With the old semantics it was possible for normal users to create
situations that only the superuser could fix.  Such as creating a
non-writable directory of files and then giving the ownership away.
Since they no longer own the files they can't change them, nor can they
remove them.  This is commonly a problem when untaring files that other
people created with restrictive file permisions.  The new semantics
avoid this problem entirely.  Therefore most systems today have been
changed to disallow giving file ownership away.  But as noted it has not
always been that way.

@c ---------------------------------------------------------------------------
@node chown fails when the username contains a '.' in it., How do I remove files that start with a '-' such as '-i'?, Why can only root chown files?, Top
@chapter chown fails when the username contains a '.' in it.

That was fixed in test releases for fileutils-4.1.  Newer versions fix
that problem.

@c ---------------------------------------------------------------------------
@node How do I remove files that start with a '-' such as '-i'?, I have a file called '--help', chown fails when the username contains a '.' in it., Top
@chapter How do I remove files that start with a '-' such as '-i'?

Since the file name begins with a '-' it looks like an option to the
command.  You need to force it to not look like an option.  Put a ./ in
the front of it.  Or give it the full file name path.  Or tell the
command you are through with options by using the double dash to end all
option processing.  This is common to most traditional UNIX commands.

@example
  rm ./-stuff
  rm /full/path/-stuff
  rm -- -stuff
@end example

And the same for other utilities too.

@example
  mv ./-stuff differentstuff
  mv -- -stuff differentstuff
@end example

@c ---------------------------------------------------------------------------
@node  I have a file called '--help', I have a file '-f' and it affects rm., How do I remove files that start with a '-' such as '-i'?, Top
@chapter I have a file called '--help', how do I remove it?

This is just a variant of the previous question.  It also applies to
files named '-i' and the like.

@example
  rm ./--help
  rm -- --help
  rm ./-i
  rm -- -i
@end example

In fact touching a file called @samp{-i} in a directory is an old trick
to avoid accidentally saying @samp{rm *} and having it remove all of the
files.  Since the @samp{*} expands to match all file names the first
such name will be the @samp{-i}.  That will make the command @samp{rm -i
file1 file2}.  As you can see that will cause @command{rm} to prompt you
and if that is not what you wanted them you can interrupt the command.
I don't personally like this and don't recommend it.


@c ---------------------------------------------------------------------------
@node  I have a file '-f' and it affects rm., Why doesn't rm -r *.pattern recurse like it should?, I have a file called '--help', Top
@chapter I have a file '-f' and it affects rm.

I have a directory containing some files and also '-f' as a filename and
@code{rm} thinks I gave it the @code{-f} option.  Why?

@example
    $ ls
    -f bar foo
    $ rm -i *
    $ ls
    -f
@end example

This is not a bug.  This is normal behavior.  The shell expands file
globs such as '*'.  The command that rm is seeing is the following.
You can test that with the echo command.  echo rm -i *

@example
  rm -i -f bar baz foo fum
@end example

The -f option to rm overrides the -i option.  Therefore the files are
removed without asking.  Since the shell expands globs like '*' before
the program sees the command line it cannot distinguish between
something the user typed and something that was expanded by the shell.
The shell filters all command lines.  This is a good thing and adds a
lot of power to the system but it means you have to know that the
shell expansion filter is there to write robust scripts and command
lines.

To robustly write a command that does what you are wanting you need to
do one of the following:

@example
  rm -i ./*
  rm -i -- *
@end example

See the previous question with regards to a filename @file{-i}.

@c ---------------------------------------------------------------------------
@node Why doesn't rm -r *.pattern recurse like it should?, Why don't the utilities have built in directory recursion?, I have a file '-f' and it affects rm., Top
@chapter Why doesn't rm -r *.pattern recurse like it should?

This question is asked a number of ways:

@example
  rm -r *.exe
  chmod -R 744 *.pl
  chown -R user:user *.html
@end example

This is the same correct behavior as other typical programs such as ls
-R, chmod -R, chown -R, etc.  Try 'ls -R *.exe', for example.  Here are
the pieces of information you need to understand what is happening.

The -r (and -R) option says that if any of the files listed on the
command line are a directory then recurse down through those
directories.  Only arguments to the program which are directories are
recursively acted upon.  So any program argument which is a directory
will be removed completely which would mean recursing down that
directory and removing anything below it.  But if the command line
argument (after shell expansion) is not a directory then it won't go
searching trying to find a match.

Here is another piece of information to understand the behavior.  The
shell interpreter is expanding the command line glob characters prior
to handing the arguments off to your command.  This is a simple form
of regular expression matching designed to make file name matching
easier.  This provides a consistent interface to all programs since
the expansion code is common to all programs by being in the
interpreting shell instead of in the program itself.  Commands in UNIX
do not see the '*.exe' or any of the shell metacharacters.  Commands
see the expanded out names which the shell found matched file names in
current directory.

The '*' is the "glob" character because it matches a glob of
characters.  But it only matches files in the current directory.  It
does not go out and list files in other directories.  The shell
matches and expands glob characters and hands of the resulting
information to the command.

You can double check this by using the echo command.  This is built
into most command shells, for example into bash.  Try echo *.exe.  Try
echo */*.exe.  In your example the first would print out *.exe if
nothing matched but would print out all file names that did match.
The command would see the result and has no idea that you provided a
wild card to match against file names.

If you want to match files in subdirectories as well then you would
need to say so explicitly with */*.exe.  The first star would match
all file names in the current directory.  Then the second *.exe would
be matching files in the subdirectories under names already matched by
the first '*' glob.

All of that was to explain why things are working as they should.  But
here is what you really want to do.  If you want to search all
directories below a location, let's say your present working
directory, then you can use other UNIX commands such as 'find' to do
so.  Here is an example, untested, use at your own peril, that would
do your rm on all .exe files below your current working directory.

Works for small numbers of files:

@example
  chgrp mygrp $(find . -name '*.html' -print)
@end example

The $(command) execute the find command, take the output of the find
command and place it right there on the command line in place of the $()
and hand the results off to the rm command.  @strong{BEWARE!}  Test this
out with the echo command prior to real usage!  Note that the '*.html'
is quoted to keep the shell from expanding it.  The find command will do
the expansion itself in this case and so the '*' needs to be hidden in a
string to keep the shell from expanding it first.

@example
  echo rm -f $(find . -name '*.exe' -print)
  echo chmod u+w $(find . -name '*.html' -print)
@end example

Unfortunately this transferal of functionality from the command to the
shell comes at a cost.  There is a limited amount of argument space
that is available for this argument expansion of file names.  It is
different on different systems and getting larger as RAM gets cheaper
but almost always there is still limit.  20KB was typical for a time
and now 2MB is common but it is a limit regardless and additionally it
is usually shared with environment variable space.  The xargs command
was designed specifically to work around this limited argument space
limit.  If you have a HUGE subdirectory with thousands of files the
above command will fail execute.  Therefore a better method is to use
find coupled with xargs.

Traditional:

@example
  find . -name '*.exe' -print | xargs chmod a+x
@end example

Robust and safer but not yet universally implemented using the -print0
option and zero terminated strings instead of newline terminated
strings:

@example
  find . -name '*.exe' -print0 | xargs -0 chmod a+x
@end example

You could substitute a full path in place of the 'find .' such as
something like 'find /class/home'.  Note that these are pretty much
equivalent to the following question which might be easier to understand
what is going on.

@c ---------------------------------------------------------------------------
@node  Why don't the utilities have built in directory recursion?, ls -d does not list directories!, Why doesn't rm -r *.pattern recurse like it should?, Top
@chapter Why don't the utilities have built in directory recursion?

@c FIXME: Need to punch up this section a lot.  It is in serious need.

People frequently wonder why
@code{cat},
@code{chgrp},
@code{chmod},
@code{chown},
@code{ls},
@code{mv},
@code{rmdir},
@code{rm},
@code{touch},
do not support @command{find} type of operations.  This is part of the
subtle but beautiful design of the UNIX system.  Programs should be
simple and modular.  Common behavior should be modularized into a common
location where it can be used by other programs.  More complicated
programs are created by chaining together simpler programs.

Here is an example of the unix philosophy in action.  Let's say you only
want to restrict directory listings to only show directories.  The
normal thing would be to use a combination of commands.  This will do
what you want.

@example
  ls -al | grep ^d
@end example

This is assuming you are using bash, some other shells such as the old
sh have ^ as being special, a synonym for |, and you would have to quote
it, this will generate the full listing and the grep would only show you
the lines starting with 'd'.  Those are the directories.  Doing this
type of command chaining is a very typical way of doing things under
unix.

When people find that particular combinations of commands are ones
that they use a lot then they will typically create a shell script, a
shell function or a shell alias which does this with a shorter name.
I like shell scripts because they are easier to pass around.  If you
found the above command one that you always used then perhaps you
would create the following shell script.

File lsdir:
@example
  #!/bin/sh
  ls -al "$@@" | grep ^d
@end example

You could call it whatever you desired.  Then it would work just like
ls but with your special behavior.  For all intents and purposes it
would be just like a normal unix command and its output could be piped
into other commands.

@c Do I really want to recommend a book in an FAQ?
@c You might like this book.  It is not the best book and so I can only
@c recommend it sparingly.  But it does capture the philosophy of unix
@c well.  The Unix Philosophy by Gancarz.  It is pretty good.  It won't
@c help you with commands like ls.  But it will point you in the right
@c direction of the spirit of unix.

@c ---------------------------------------------------------------------------
@node  ls -d does not list directories!, Argument list too long, Why don't the utilities have built in directory recursion?, Top
@chapter ls -d does not list directories!

I typed in @kbd{ls -dl} but it only showed me the current directory.

Well, yes, that is what it is supposed to do.  The default directory to
list if none is specified is the current directory.  The -d option
prevents recursively listing the directory.  Therefore ls -ld lists only
attributes of the current directory.

But I expected to see all of the directories.

That would be the output of 'ls -l' without the -d option.

The -d option is meant to prevent ls from listing the contents of
directories when you only wnat it to list the names of the
directories.

To understand the usefulness of the -d option try this example.
Compare the differences in the results of ls when you use the -d
option versus when you do not.

@example
  ls -ld /etc/*.d
  ls -l /etc/*.d
@end example

If you are trying to find files in the directory hierarchy then you
should look into using the @command{find} command.  It is very powerful
and contains an interface which can be used with many other progams.

@example
  info find
@end example

@c ---------------------------------------------------------------------------
@node Argument list too long, I am trying to compile a C program ..., ls -d does not list directories!, Top
@chapter Argument list too long

I tried to move about 5000 files with mv, but it said:
@example
  bash: /bin/mv: Argument list too long
@end example

The UNIX operating system tradionally has a fixed limit for the amount
of memory that can be used for a program environment and argument list
combined.  You can use getconf to return that limit.  On my Linux system
(2.2.12) that amount is 128k.  On my HP-UX system (11.0) that amount is
2M.  It can vary per operating system.  POSIX only requires 20k which
was the traditional value used for probably 20 years.  Newer operating
systems releases usually increase that somewhat.

@example
  getconf ARG_MAX
  131072
@end example

Note that your message came from "bash" your shell command line
interpreter.  Its job is to expand command line wildcard characters
that match filenames.  It expands them before any program can see
them.  This is therefore common to all programs on most UNIX-like
operating systems.  It cannot exceed the OS limit of ARG_MAX and if it
tries to do so the error "Argument list too long" is returned to the
shell and the shell returns it to you.

This is not a bug in 'mv' or other utilitities nor is it a bug in 'bash'
or any other shell.  It is an architecture limitation of UNIX-like
operating systems.  The 'mv' program was prevented by the OS from
running and the shell is just the one in the middle reporting the
problem. The shell tried to load the program but the OS ran out of
space.  However, this problem is one that is easily worked around using
the supplied utilities.  Please review the documentation on 'find' and
'xargs' for one possible combination of programs that work well.

You might think about increasing the value of ARG_MAX but I advise
against it.  Any limit, even if large, is still a limit.  As long as it
exists then it should be worked around for robust script operation.  On
the command line most of us ignore it unless we exceed it at which time
we fall back to more robust methods.

Here is an example using chmod where exceeding ARG_MAX argument length
is avoided.

@example
  find htdocs -name '*.html' -print0 | xargs -0 chmod a+r
@end example

Read the previous question for another facet of this problem.

@c ---------------------------------------------------------------------------
@node  I am trying to compile a C program ..., I am having a problem with kill, Argument list too long, Top
@chapter I am trying to compile a C program program ...

This frequently occurs with a question such as, I have found a bug in
the sleep() function, or, I am trying to use the chown() function in my
program.  That may well be true.  But those library functions are not
the same as the command line programs.  The command line program in the
GNU utilities are also C program and just like your program are using
the same C library and operating system calls.  But we can't help you
with your problem since that code is in the system's C library and not
in any of the utility packages.

Sometimes the same name is used for both a program and a system call.
In fact most of the programs got their names because that was what the
system call was named.  One caused the other.  Which means that it is
very likely that the @command{sleep} program was named because it used
the @code{sleep} library routine.

This usually happens with
@code{chgrp},
@code{chmod},
@code{chown},
@code{mkdir},
@code{mknod},
@code{nice},
@code{rmdir},
@code{sleep},
@code{sync},
@code{uname},
or one of the other programs that have a name matching a C programming
routine.  It can be confusing to realize that the program is a wrapper
to the underlying library routine or system call.  If you are compiling
a program then you are @strong{NOT} using the GNU command line utility
in your C/C++ program.  You could be using the GNU command line utility
in your shell script, however.

You may be confusing the C library routine used in your program with the
shell command line program.  They are not related.  Except that the
program calls the library function just like your program does.  If you
have a real bug in the library routine then you need to determine who
supplied that library and report the bug to them.  If it is the GNU Lib
C, a.k.a. glibc, provided library then the glibc mailing list at
@uref{mailto:bug-glibc@@gnu.org,<bug-glibc@@gnu.org>} might be a useful
future reference.

The online man pages can also be confusing in regard to this.  If you
are trying to use chown() in a program and get a man page you will
likely get the man page for the command line program and not the library
routine you were looking for.  You must specify the @strong{section} of
the manual that you want information.

@example
  man chown
  man 2 chown
  man sleep
  man 3 sleep
@end example

Traditionally man pages are organized by section number.  Section 1 are
command line programs.  Section 2 are operating system calls, aka kernel
calls.  Section 3 are library routines.  Library routines may or may not
use system calls.  Etc.  Other sections are used for other purposes that
are not germane here.

Many GNU programs have deprecated the @command{man} pages and have moved
entirely to @command{info} documentation.  But man pages still have a
loyal following and are quite useful for reference.  But they make poor
user guides.

@c ---------------------------------------------------------------------------
@node  I am having a problem with kill, Sort does not sorting in normal order!, I am trying to compile a C program ..., Top
@chapter I am having a problem with kill, nice, pwd, sleep, or test.

This is frequently a variant of the previous question.  Go read it first
and then come back here.  This time the same name is used by a utility
and is also built into a command line shell.  In which case you might
need to report your problem to your shell maintainers.

Many commands are built into your command shell so as to speed up shell
scripts.  People frequently get confused over whether they are running
the external program or the internal shell built in.  This usually
happens with
@code{kill},
@code{nice},
@code{pwd},
@code{printf},
@code{sleep},
@code{test},
and some others that exist both as internal and external commands.
Double check that the problem you are having is with the external
program.  If it is the internal version then contemplate reporting it to
@uref{bug-bash@@gnu.org, <bug-bash@@gnu.org>}.

Many times a program is required by circumstances to exist both as a
builtin and as an external.  Usually this is because of the need to be
exec'd directly from another program without a shell to implement it as
a builtin.  Therefore it must exist as an external, standalone utility.
However, those utilities are also built into most shells in order to
improve the speed performance.

@c ---------------------------------------------------------------------------
@node  Sort does not sorting in normal order!, The ls command is not listing files in a normal order!, I am having a problem with kill, Top
@chapter Sort does not sorting in normal order!

This one question arises almost more often than any other.  It is due to
a very popular Linux distribution setting LANG=en_US in your user
environment without your knowledge.  At that point sort appears broken.
But once specifically requested by LANG and others like LC_* variables,
sort and other locale knowledgable programs @strong{must} respect that
setting and sort according to the operating system locale tables.

Of course those tables are a blessing to non-english speaking computer
users.  Many languages use non-ASCII fonts and character sets.  The
POSIX standards and the GNU utilities support those by using the
installed system library sorting routines.  By using them languages can
specify a specific ordering.  This can be done by a translator well
after the program has been written and by translators not known by the
program author.  It is a dynamic change to the program.  However, when
those tables are incorrect it can also break a perfectly correct
program.  When locale tables are broken this is most noticable with the
sort command so it bears the full force of the problem.

Here is the standard mailing list reply on this topic.

This is due to the fact that you or your vendor have set environment
variables that direct the program to use locale specific sorting
tables which do not sort as you expect.  You or your vendor have
probably set environment variables like LANG, LC_ALL, or LANG to
en_US.  There appears to be a problem with that table on some systems
which is not part of the GNU program but part of your vendor's system
release.

Unset them, and then set LC_ALL to POSIX.

@example
  # If you use bash or some other Bourne-based shell,
  export LC_ALL=POSIX

  # If you use a C-shell,
  setenv LC_ALL POSIX
@end example

and it will then work the way you expect because it will use a
different set of tables.

See the standards documentation for more information on the locale
variables with regards to sort.

@uref{http://www.unix-systems.org/single_unix_specification_v2/xcu/sort.html}

@c ---------------------------------------------------------------------------
@node  The ls command is not listing files in a normal order!, The date command is not working right., Sort does not sorting in normal order!, Top
@chapter The ls command is not listing files in a normal order!

This is just a variant of the previous question.  Any program that is
compliant with the standards and implements locale based collating
sequences to support non-ascii languages will be affected.

See the standards documentation for more information on the locale
variables with regards to ls.

@uref{http://www.unix-systems.org/single_unix_specification_v2/xcu/ls.html}

@c ---------------------------------------------------------------------------
@node  The date command is not working right., ln -s did not link my files together, The ls command is not listing files in a normal order!, Top
@chapter The date command is not working right.

If you are using date version 2.0 or earlier that is certainly
possible.  A large number of bug fixes and improvements went into the
sh-utils-2.0.11 around October 2000.  Please install a newer version of
the code.  The test release versions at
@uref{ftp://alpha.gnu.org/gnu/fetish} are best.

@c ---------------------------------------------------------------------------
@node  ln -s did not link my files together, How do I change the ownership or permissions of a symlink?, The date command is not working right., Top
@chapter ln -s did not link my files together

@c Hmm...  This just does not convey the problem I was trying to answer.

Symbolic links are created with ln -s.  That creates a name redirection.
When a symlink is accessed the filesystem will take the contents of the
symlink as a redirection to another file, where the process may
recursively be continued many times.  If you were meaning "ln -s a /c/b"
then that would create /c/b which would be a relative symlink to file
"/c/a".  If /c/a did not exist then this would be dangling until such
time at that file was created.  The owner, group and mode of a symlink
are not significant to file access through it.

Symbolic links may use either absolute or relative paths but there are
tradeoffs.  Generally I advocate making only relative links so that
the location is network independent and will work desirably across NFS
mounted filesystems.

@c ---------------------------------------------------------------------------
@node  How do I change the ownership or permissions of a symlink?, Value too large for defined data type, ln -s did not link my files together, Top
@chapter How do I change the ownership or permissions of a symlink?

The owner, group, and permissions of a symlink are not in any way
significant.  Only the value of the symlink is meaningful.  Regardless
of that some operating systems will allow you change the owner, group or
mode of a symlink and other operating systems will not.  Do not worry
about it as it does not matter in any case.

@c ---------------------------------------------------------------------------
@node  Value too large for defined data type, Tar created a Large File but I can't remove it., How do I change the ownership or permissions of a symlink?, Top
@chapter Value too large for defined data type

It means that your version of the utilities were not compiled with large
file support enabled.  The GNU utilities do support large files if they
are compiled to do so.  You may want to compile them up again and make
sure that large file support is enabled.  This support is automatically
configured by autoconf on most systems.  But it is possible that on your
particular system it could not determine how to do that and therefore
autoconf concluded that your system did not support large files.

The message "Value too large for defined data type" is a system error
message reported when an operation on a large file is attempted using a
non-large file data type.  Large files are defined as anything larger
than a signed 32-bit integer, or stated differently, larger than 2GB.

Many system calls that deal with files return values in a "long int"
data type.  On 32-bit hardware a long int is 32-bits and therefore this
imposes a 2GB limit on the size of files.  When this was invented that
was @strong{HUGE} and it was hard to conceive of needing anything that
large.  Time has passed and files can be much larger today.  On native
64-bit systems the file size limit is usually 2GB * 2GB.  Which we will
again think is huge.

You may see that on a 32-bit system with a 32-bit "long int" you can't
make it any bigger.  At least not and maintain compatibility with
previous programs.  Changing that would break many things!  But many
systems make it is possible to switch into a new program mode which
rewrites all of the file operations into a 64-bit program model.
Instead of "long" they use a new data type called "off_t" which is
constructed to be 64-bits in size.  Program source code must be written
to use the off_t data type instead of the long data type.  This is
typically done by defining -D_FILE_OFFSET_BITS=64 or some such.  It is
stysem dependent.  Once done and once switched into this new mode most
programs will support large files just fine.

See the next question if you have inadvertantly created a large file and
now need some way to deal with it.

@c ---------------------------------------------------------------------------
@node Tar created a Large File but I can't remove it.,  , Value too large for defined data type, Top
@chapter Tar created a Large File but I can't remove it.

I created a file with tar cvf backup.tar.  Trying to "rm" this file this
is not possible.  The error message is:

@example
  rm: cannot remove `backup.tar': Value too large for defined data
@end example

What could I do to remove that file ?

Sometimes one utility such as @command{tar} will be compiled with large
file support while another utility like @command{rm} will be compiled
without.  It happens.  Which means you might find yourself with a large
file created by one utility but unable to work with it with another.

At this point we need to be clever.  Find a utility that can operate on
a large file and use it to truncate the file.  Here are several examples
of how to work around this problem.  Of course in a perfect world you
would recompile the utilities to support large files and not worry about
needing a workaround.

This example again requires perl to be configured for large files.

@example
  perl -e 'unlink("backup.tar");'
@end example

So let's try to hit it more directly.  Truncate the file first.  That
will make it small and then you can remove it.  The shell will do this
when redirecting the output of commands.

@example
  true > backup.tar
  rm backup.tar
@end example

However, if your shell was not compiled for large files then the
redirection will fail.  In that case we have to resort to more subtle
methods.  Since tar created the file then tar must be configured to
support large files.  Use that to your advantage to truncate the file.

@example
  touch /tmp/junk
  tar cvf backup.tar /tmp/junk
@end example

@c ---------------------------------------------------------------------------
@bye
